name: build-deploy
on:
  push:
    branches:
      - source
  pull_request:
    branches:
      - source
  schedule:
    # Weekly full topic discovery on Sundays at 2 AM UTC
    - cron: "0 2 * * 0"
  workflow_dispatch:
    inputs:
      topic_mode:
        description: "Topic extraction mode"
        required: false
        default: "auto"
        type: choice
        options:
          - auto
          - metadata-only
          - full-discovery
          - force
      deploy:
        description: "Deploy to GitHub Pages"
        required: false
        default: true
        type: boolean
jobs:
  setup-and-detect-changes:
    name: Setup & Change Detection
    runs-on: ubuntu-latest
    outputs:
      blog_changed: ${{ steps.change-detection.outputs.blog_changed }}
      topic_mode: ${{ steps.topic-mode.outputs.topic_mode }}
      topic_reason: ${{ steps.topic-mode.outputs.reason }}
      blog_hash: ${{ steps.blog-hash.outputs.hash }}
      requirements_hash: ${{ steps.requirements-hash.outputs.hash }}
    steps:
      - name: Extract Branch Name
        run: echo "BRANCH=$(echo ${GITHUB_REF##*/})" >> $GITHUB_ENV

      - name: Checkout Repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
        with:
          fetch-depth: 0 # Need full history for change detection

      - name: Get Requirements Hash
        id: requirements-hash
        run: echo "hash=${{ hashFiles('website/scripts/python-requirements.txt') }}" >> $GITHUB_OUTPUT

      - name: Get Blog Content Hash
        id: blog-hash
        run: |
          # Create hash of blog content for topic model caching
          BLOG_HASH=$(find blog -name "*.md" -type f -exec sha256sum {} \; | sha256sum | cut -d' ' -f1)
          echo "hash=${BLOG_HASH}" >> $GITHUB_OUTPUT
          echo "Blog content hash: ${BLOG_HASH}"

      - name: Detect File Changes
        id: change-detection
        run: |
          echo "Analyzing file changes to determine processing scope..."

          # Initialize defaults
          BLOG_CHANGED=false

          # Check manual workflow dispatch input
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "Manual workflow dispatch - will respect topic_mode input"
            BLOG_CHANGED=true  # Process content for manual runs
          fi

          # Check for scheduled run (weekly full discovery)
          if [ "${{ github.event_name }}" = "schedule" ]; then
            echo "Scheduled run - full processing required"
            BLOG_CHANGED=true
          fi

          # Check for blog content changes in push events
          if [ "${{ github.event_name }}" = "push" ] && [ "${{ github.event.before }}" != "0000000000000000000000000000000000000000" ]; then
            if git diff --name-only ${{ github.event.before }}..${{ github.sha }} | grep -q "^blog/"; then
              echo "Blog content changes detected"
              BLOG_CHANGED=true
            else
              echo "No blog content changes detected"
              BLOG_CHANGED=false
            fi
          elif [ "${{ github.event_name }}" = "push" ]; then
            # First commit - process content
            echo "Initial commit - processing content"
            BLOG_CHANGED=true
          fi

          echo "blog_changed=${BLOG_CHANGED}" >> $GITHUB_OUTPUT
          echo "üîç Blog content processing required: ${BLOG_CHANGED}"

      - name: Determine Topic Extraction Mode
        id: topic-mode
        run: |
          # Initialize variables
          TOPIC_MODE="metadata-only"
          REASON="default fast mode"
          BLOG_CHANGED="${{ steps.change-detection.outputs.blog_changed }}"

          # Check manual workflow dispatch input
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            MANUAL_MODE="${{ inputs.topic_mode }}"
            if [ "$MANUAL_MODE" != "auto" ]; then
              TOPIC_MODE="$MANUAL_MODE"
              REASON="manual workflow dispatch: $MANUAL_MODE"
            fi
          fi

          # Check for scheduled run (weekly full discovery)
          if [ "${{ github.event_name }}" = "schedule" ]; then
            TOPIC_MODE="full-discovery"
            REASON="scheduled weekly full discovery"
          fi

          # Check commit message for manual triggers
          COMMIT_MSG="${{ github.event.head_commit.message }}"
          if [[ "$COMMIT_MSG" == *"[full-topics]"* ]]; then
            TOPIC_MODE="full-discovery"
            REASON="commit message contains [full-topics]"
          elif [[ "$COMMIT_MSG" == *"[force-topics]"* ]]; then
            TOPIC_MODE="force"
            REASON="commit message contains [force-topics]"
          fi

          # Auto-detect based on blog content changes
          if [ "$TOPIC_MODE" = "metadata-only" ] && [ "$BLOG_CHANGED" = "true" ]; then
            TOPIC_MODE="full-discovery"
            REASON="blog content changes detected"
          fi

          # Fast path optimization - if no blog changes, use cached metadata mode
          if [ "$BLOG_CHANGED" = "false" ] && [ "$TOPIC_MODE" = "metadata-only" ]; then
            TOPIC_MODE="use-cached"
            REASON="no blog changes - use cached metadata"
          fi

          echo "topic_mode=$TOPIC_MODE" >> $GITHUB_OUTPUT
          echo "reason=$REASON" >> $GITHUB_OUTPUT
          echo "üéØ Topic extraction mode: $TOPIC_MODE ($REASON)"

  # Job for content processing - always runs to ensure metadata exists
  process-content:
    name: Process Blog Content
    runs-on: ubuntu-latest
    needs: setup-and-detect-changes
    steps:
      - name: Checkout Repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          architecture: "x64"

      - name: Cache Python Virtual Environment
        uses: actions/cache@v4
        with:
          path: .venv
          key: python-venv-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.requirements_hash }}-v2
          restore-keys: |
            python-venv-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.requirements_hash }}-
            python-venv-${{ runner.os }}-

      - name: Cache Pip Wheel Cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-cache-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.requirements_hash }}
          restore-keys: |
            pip-cache-${{ runner.os }}-

      - name: Cache NLTK Data
        uses: actions/cache@v4
        with:
          path: ~/nltk_data
          key: nltk-data-${{ runner.os }}-v3
          restore-keys: |
            nltk-data-${{ runner.os }}-v3-
            nltk-data-${{ runner.os }}-

      - name: Cache Hugging Face Transformers
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: huggingface-transformers-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.requirements_hash }}-v2
          restore-keys: |
            huggingface-transformers-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.requirements_hash }}-
            huggingface-transformers-${{ runner.os }}-

      - name: Cache Topic Models
        uses: actions/cache@v4
        with:
          path: website/config/topic_models
          key: topic-models-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.blog_hash }}-v2
          restore-keys: |
            topic-models-${{ runner.os }}-${{ needs.setup-and-detect-changes.outputs.blog_hash }}-
            topic-models-${{ runner.os }}-

      - name: Setup Topic Extraction System
        run: |
          chmod +x ./scripts/setup-topic-extraction.sh
          if [ "${{ needs.setup-and-detect-changes.outputs.topic_mode }}" = "full-discovery" ]; then
            ./scripts/setup-topic-extraction.sh
          else
            ./scripts/setup-topic-extraction.sh --skip-discovery
          fi
        env:
          PYTHONIOENCODING: utf-8
          LC_ALL: C.UTF-8
          LANG: C.UTF-8
          TOKENIZERS_PARALLELISM: false
          HF_HOME: ~/.cache/huggingface
          PIP_CACHE_DIR: ~/.cache/pip
          PIP_DISABLE_PIP_VERSION_CHECK: 1
          PIP_NO_COMPILE: 1
          PIP_PREFER_BINARY: 1

      - name: Generate Blog Metadata with Smart Topic Extraction
        run: |
          chmod +x ./scripts/update-blog-metadata.sh

          MODE="${{ needs.setup-and-detect-changes.outputs.topic_mode }}"
          case "$MODE" in
            "use-cached")
              echo "üöÄ Using cached metadata - no processing needed..."
              ./scripts/update-blog-metadata.sh --metadata-only --skip-topics
              ;;
            "metadata-minimal")
              echo "üöÄ Running minimal metadata generation (no topic processing)..."
              ./scripts/update-blog-metadata.sh --metadata-only --skip-topics
              ;;
            "metadata-only")
              echo "üöÄ Running fast metadata-only update..."
              ./scripts/update-blog-metadata.sh --metadata-only
              ;;
            "full-discovery")
              echo "üîç Running full topic discovery and metadata generation..."
              ./scripts/update-blog-metadata.sh
              ;;
            "force")
              echo "‚ö° Running forced complete regeneration..."
              ./scripts/update-blog-metadata.sh --force
              ;;
            *)
              echo "‚ùå Unknown topic mode: $MODE"
              exit 1
              ;;
          esac
        env:
          PYTHONIOENCODING: utf-8
          LC_ALL: C.UTF-8
          LANG: C.UTF-8

      - name: Verify Metadata Generation
        run: |
          if [ ! -f "website/public/blogdata/metadata/blog_metadata.json" ]; then
            echo "Error: Blog metadata file was not generated"
            exit 1
          fi
          echo "‚úÖ Blog metadata generated successfully"

      - name: Upload Blog Content and Metadata Artifact
        uses: actions/upload-artifact@v4
        with:
          name: blog-metadata
          path: |
            website/public/blogdata/
            website/config/topic_models/
          retention-days: 1

  # Parallel job for Node.js build
  build-site:
    name: Build Static Site
    runs-on: ubuntu-latest
    needs: [setup-and-detect-changes, process-content]
    if: always() && needs.process-content.result == 'success'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: latest
          cache: "npm"
          cache-dependency-path: website/package-lock.json

      - name: Setup Python (for validation)
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Download Blog Content and Metadata
        uses: actions/download-artifact@v5
        with:
          name: blog-metadata
          path: website/

      - name: Validate Blog Content and Metadata
        run: |
          echo "üîç Validating blog content and metadata for build..."

          # Check if metadata was downloaded from artifact
          if [ -f "website/public/blogdata/metadata/blog_metadata.json" ]; then
            echo "‚úÖ Blog metadata found"

            # Validate metadata file is valid JSON and not empty
            if python -c "import json; data=json.load(open('website/public/blogdata/metadata/blog_metadata.json')); assert len(data) >= 0" 2>/dev/null; then
              METADATA_SIZE=$(wc -c < website/public/blogdata/metadata/blog_metadata.json)
              METADATA_POSTS=$(python -c "import json; data=json.load(open('website/public/blogdata/metadata/blog_metadata.json')); print(len(data))" 2>/dev/null || echo "0")
              echo "‚úÖ Metadata validated: ${METADATA_SIZE} bytes, ${METADATA_POSTS} posts"

              # Check if it's just empty array (minimal metadata)
              if [ "$METADATA_POSTS" = "0" ]; then
                echo "‚ö†Ô∏è  Using minimal metadata - build will have limited blog functionality"
              fi
            else
              echo "‚ùå Metadata file is invalid JSON - creating emergency fallback"
              echo "[]" > website/public/blogdata/metadata/blog_metadata.json
            fi
          else
            echo "‚ùå Blog metadata not found - this should not happen!"
            echo "Creating emergency fallback metadata..."
            mkdir -p website/public/blogdata/metadata/
            echo "[]" > website/public/blogdata/metadata/blog_metadata.json
            echo "‚ö†Ô∏è  Using empty metadata - build may have missing content"
          fi

          # Validate blog content files exist
          BLOG_FILE_COUNT=$(find website/public/blogdata -name "*.md" -type f | wc -l)
          if [ "$BLOG_FILE_COUNT" -gt 0 ]; then
            echo "‚úÖ Found $BLOG_FILE_COUNT blog content files"
          else
            echo "‚ö†Ô∏è  No blog content files found - this may indicate an artifact transfer issue"
          fi

          # Final verification
          if [ ! -f "website/public/blogdata/metadata/blog_metadata.json" ]; then
            echo "‚ùå FATAL: Could not ensure metadata file exists"
            exit 1
          else
            echo "‚úÖ Blog content and metadata validation complete - build can proceed"
          fi

      - name: Display Versions
        run: |
          echo "Node version: $(node --version)"
          echo "NPM version: $(npm --version)"

      - name: Install Node Dependencies
        working-directory: website
        run: npm ci

      - name: Get Highlight.js Stylesheets
        working-directory: website
        run: npm run getHighlightJsStyleSheets

      - name: Generate Static Site
        working-directory: website
        run: npm run generate

      - name: Verify Build Output
        run: |
          if [ ! -d "website/.output/public" ]; then
            echo "Error: Build output directory not found"
            exit 1
          fi
          echo "‚úÖ Static site generated successfully"

      - name: Upload Build Artifact
        uses: actions/upload-artifact@v4
        with:
          name: static-site
          path: website/.output/public/
          retention-days: 1

  # Final deployment job
  deploy:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    needs: [setup-and-detect-changes, build-site]
    if: |
      always() &&
      needs.build-site.result == 'success' &&
      (
        (github.event_name == 'push' && github.ref_name == 'source') ||
        (github.event_name == 'schedule') ||
        (github.event_name == 'workflow_dispatch' && inputs.deploy == true)
      )
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Download Build Artifact
        uses: actions/download-artifact@v5
        with:
          name: static-site
          path: ./public

      - name: Deploy to GitHub Pages
        id: deployment
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: main
          keep_files: false
          force_orphan: true
          commit_message: |
            GitHub CI Updates [ci skip]

            Topic extraction mode: ${{ needs.setup-and-detect-changes.outputs.topic_mode }}
            Reason: ${{ needs.setup-and-detect-changes.outputs.topic_reason }}
            Triggered by: ${{ github.event_name }}
