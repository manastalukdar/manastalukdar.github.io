---
published: false
tags:
 - Artificial Intelligence
 - Machine Learning
 - Papers I Read Recently Series
 - Reading
 - Generative AI
 - Synthetic Data
 - Data Generation
 - Synthetic Data Generation
 - Large Language Models
 - Model Training
 - Model Evaluation
 - LLM as Judge
 - Alignment with Human Feedback
 - Agentic AI
 - AI Agents
categories:
 - Technology
authors:
 - "Manas Talukdar"
post-format: link
title: Recent AI Reading [dd Month yyyy]
url-slug: recent-ai-reading-dd-month-yyyy
first-published-on: 2024-09-07 20:06
last-updated-on: 2024-09-07 20:06
meta:
 description: "Recent AI reading, including papers and articles."
excerpt: ""
---

# Recent AI Reading [dd Month yyyy]

## Papers

### Agentic AI / AI Agents

- [Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research](https://arxiv.org/abs/2502.04644)
- [A-MEM: Agentic Memory for LLM Agents](https://arxiv.org/abs/2502.12110v3)
- [Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks](https://arxiv.org/abs/2503.09572)
- [Why Do Multi-Agent LLM Systems Fail?](https://arxiv.org/abs/2503.13657)
- [Survey on Evaluation of LLM-based Agents](https://arxiv.org/abs/2503.16416)
- [Large Language Model Agent: A Survey on Methodology, Applications and Challenges](https://arxiv.org/abs/2503.21460)
- [How to think about agent frameworks](https://blog.langchain.dev/how-to-think-about-agent-frameworks/)
  - [Agent Framework comparison](https://docs.google.com/spreadsheets/d/1B37VxTBuGLeTSPVWtz7UMsCdtXrqV5hCjWkbHN8tfAo/edit?gid=0#gid=0)
- [Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems](https://arxiv.org/abs/2504.01990)
- [AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge](https://arxiv.org/abs/2505.10468)

### AI Alignment with Human Feedback and Preferences, and other methods

- [PILAF: Optimal Human Preference Sampling for Reward Modeling](https://arxiv.org/abs/2502.04270)
- [Aligning Multimodal LLM with Human Preference: A Survey](https://arxiv.org/abs/2503.14504)
- [Boost Your Human Image Generation Model via Direct Preference Optimization](https://arxiv.org/abs/2405.20216)
- [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org/abs/2504.20571)
  - GitHub [repo](https://github.com/ypwang61/One-Shot-RLVR)
- [AlphaPO -- Reward shape matters for LLM alignment](https://arxiv.org/abs/2501.03884)

### Large Language Models

- [Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback](https://arxiv.org/abs/2501.10799)
- [NoLiMa: Long-Context Evaluation Beyond Literal Matching](https://arxiv.org/abs/2502.05167)
- [Competitive Programming with Large Reasoning Models](https://arxiv.org/abs/2502.06807)
- [Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model](https://arxiv.org/abs/2502.10248)
- [GPT-4.5 System Card](https://huggingface.co/reach-vb/GPT-4.5-System-Card/blob/main/gpt-4-5-system-card.pdf)
  - <https://cdn.openai.com/gpt-4-5-system-card.pdf>
- [CodeCriticBench: A Holistic Code Critique Benchmark for Large Language Models](https://arxiv.org/abs/2502.16614v1)
- [LLM Post-Training: A Deep Dive into Reasoning Large Language Models](https://arxiv.org/abs/2502.21321)
- [Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models](https://arxiv.org/abs/2503.09567)
- [Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning](https://arxiv.org/abs/2503.09516)
- [A Survey on Post-training of Large Language Models](https://arxiv.org/abs/2503.06072)
- [Measuring AI Ability to Complete Long Tasks](https://arxiv.org/abs/2503.14499)
  - [Blog: Measuring AI Ability to Complete Long Tasks](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/)
- [Auditing Language Models for Hidden Objectives](https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf)
- [On the Biology of a Large Language Model](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)
  - Blog: [Tracing the thoughts of a large language model](https://www.anthropic.com/news/tracing-thoughts-language-model)
  - YouTube Video: [Tracing the thoughts of a large language model](https://www.youtube.com/watch?v=Bj9BD2D3DzA)
- [Taming the Titans: A Survey of Efficient LLM Inference Serving](https://arxiv.org/abs/2504.19720)
- [LLMs for Engineering: Teaching Models to Design High Powered Rockets](https://arxiv.org/abs/2504.19394)
- [LLMs Get Lost In Multi-Turn Conversation](https://arxiv.org/abs/2505.06120)

### Model Evaluation

### Retrieval-Augmented Generation-

- [UniversalRAG: Retrieval-Augmented Generation over Multiple Corpora with Diverse Modalities and Granularities](https://arxiv.org/abs/2504.20734)

### Synthetic Data

- [Generative Agent Simulations of 1,000 People](https://arxiv.org/abs/2411.10109)

### Miscellaneous

- [Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2](https://arxiv.org/abs/2502.03544)
- [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2301.08243)
- [Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach](https://arxiv.org/abs/2502.05171)
- [Applications of Large Models in Medicine](https://arxiv.org/abs/2502.17132)

## Technical Reports

- [Gemma 3 Technical Report](https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf)
- [Artificial Intelligence Index Report 2025](https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf) from Stanford University.

## Articles and Blog Posts

- [When Doctors With A.I. Are Outperformed by A.I. Alone](https://erictopol.substack.com/p/when-doctors-with-ai-are-outperformed)
- [Crossing the uncanny valley of conversational voice](https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice)
- [Reinforcement Learning from Verifiable Rewards](https://labelstud.io/blog/reinforcement-learning-from-verifiable-rewards/)

## Miscellaneous

- [Traveling Waves Integrate Spatial Information Through Time](https://arxiv.org/abs/2502.06034)
- [Transformers without Normalization](https://arxiv.org/abs/2503.10622)
- [GPT Researcher](https://gptr.dev) | [Source Code in GitHub](https://github.com/assafelovic/gpt-researcher)
- [Dive into Deep Learning](https://arxiv.org/abs/2106.11342)
