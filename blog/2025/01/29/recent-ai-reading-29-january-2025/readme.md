---
published: true
tags:
 - Artificial Intelligence
 - Machine Learning
 - Papers I Read Recently Series
 - Reading
 - Generative AI
 - Large Language Models
 - Agentic AI
categories:
 - Technology
authors:
 - "Manas Talukdar"
post-format: link
title: Recent AI Reading [29 January 2025]
url-slug: recent-ai-reading-29-january-2025
first-published-on: 2025-01-29 11:25
last-updated-on: 2025-02-06 22:25
meta:
 description: "Recent AI reading, including papers and articles."
excerpt: "Reasoning Language Models: A Blueprint"
---

# Recent AI Reading [29 January 2025]

## Papers

### Agentic AI

- [A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning](https://arxiv.org/abs/2406.05804)

### Large Language Models

- [Foundations of Large Language Models](https://arxiv.org/abs/2501.09223v1)
  - [GitHub repo](https://github.com/xinzhel/LLM-Agent-Survey)
- [Large Language Models: A Survey](https://arxiv.org/abs/2402.06196)
- [Reasoning Language Models: A Blueprint](https://arxiv.org/abs/2501.11223)
- [Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models](https://www.alphaxiv.org/abs/2501.09686v2)
- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)
- [Bite: How Deepseek R1 was trained](https://www.philschmid.de/deepseek-r1)
- [Breaking down the DeepSeek-R1 training process—no PhD required](https://www.vellum.ai/blog/the-training-of-deepseek-r1-and-ways-to-use-it)
- [DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437)
- [DeepSeek R1 and R1-Zero Explained](https://thelmbook.com/articles/#!./DeepSeek-R1.md)
- [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)
  - <https://x.com/N8Programs/status/1884110306089357361>
- [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314)
- [Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models](https://arxiv.org/abs/2406.02061)
  - <https://x.com/JJitsev/status/1883158738661691878>
- [s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)
  - [Researchers created an open rival to OpenAI’s o1 ‘reasoning’ model for under $50](https://techcrunch.com/2025/02/05/researchers-created-an-open-rival-to-openais-o1-reasoning-model-for-under-50/?guccounter=1)

## Technical Reports

- [Qwen2.5-1M Technical Report](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-1M/Qwen2_5_1M_Technical_Report.pdf)
  - [Qwen2.5-1M: Deploy Your Own Qwen with Context Length up to 1M Tokens](https://qwenlm.github.io/blog/qwen2.5-1m/)
- [DeepSeek R1 Read Teaming Report](https://cdn.prod.website-files.com/6690a78074d86ca0ad978007/679918c4e37c71ea2179f6fb_Latest%20Red%20Teaming%20Deepseek_Jan2025.pdf) from Enkrypt AI.

## Articles and Blog Posts

- [How to align open LLMs in 2025 with DPO & and synthetic data](https://www.philschmid.de/rl-with-llms-in-2025-dpo)

## Miscellaneous

- [International AI Safety Report](https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf) 

